{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1d33bcc",
   "metadata": {},
   "source": [
    "## Approaches on how to represent text embedding data\n",
    "\n",
    "* Use padding and transpose the embeddings to make sure that:\n",
    "    1. No information is lost\n",
    "    2. Spatial integrity is maintained for the most part\n",
    "    3. Although this results in a huge sparse matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5bb57e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from math import sqrt, floor, ceil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "33d98f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def isPerfectSquare(n):\n",
    "    if (ceil(sqrt(n)) == floor(sqrt(n))):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def nextPerfectSquare(num):\n",
    "    \"\"\"\n",
    "    Gets you the next perfect square from a given number\n",
    "    \"\"\"\n",
    "    orig = num\n",
    "    limit = num + 1000\n",
    "    while num < limit:\n",
    "        if isPerfectSquare(num):\n",
    "            print(f\"{num} is the next perfect square\")\n",
    "            return num\n",
    "        num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c930ac84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \"\"\"\n",
    "    Loads the embeddings saved in npz format into memory and convert into torch tensors\n",
    "    \"\"\"\n",
    "    img_emb = np.load(\"working/image_embeddings_large.npy\", allow_pickle=True)\n",
    "    text_emb = np.load(\"working/text_embeddings_large.npy\", allow_pickle=True)\n",
    "    \n",
    "    img_embeddings = [torch.from_numpy(np_arr) for np_arr in img_emb]\n",
    "    text_embeddings = [torch.from_numpy(np_arr) for np_arr in text_emb]\n",
    "    \n",
    "    return img_embeddings, text_embeddings\n",
    "\n",
    "img_emb, text_emb = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "888ae981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 768])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_emb[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d187b5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0580, -0.2076, -0.1875,  ..., -0.0379,  0.3235,  0.1966],\n",
       "        [ 0.4263, -0.3844, -0.4158,  ..., -0.1270,  0.5972, -0.0761],\n",
       "        [-0.1596, -0.1977, -0.0715,  ..., -0.3146,  0.0337, -0.5706],\n",
       "        ...,\n",
       "        [ 0.6532, -0.1045, -0.3341,  ..., -0.2913, -0.0313, -0.1788],\n",
       "        [ 0.1402, -0.7515, -0.4805,  ...,  0.2352,  0.0075, -0.6129],\n",
       "        [ 0.8141,  0.0583, -0.4363,  ..., -0.0272, -0.3467, -0.4803]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_emb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f60cd676",
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_patches(image_shape, patch_shape):\n",
    "    \"\"\"\n",
    "    Expects image shape to be -> [H, W, C] (channels last format)\n",
    "    \"\"\"\n",
    "    res = (image_shape[0] * image_shape[1]) / (patch_shape ** 2)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "91632741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "576.0"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_patches(\n",
    "    image_shape=(768, 768),\n",
    "    patch_shape=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "831278da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5376"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = text_emb[0]\n",
    "a.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "28cb56a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768, 768]) 589824\n"
     ]
    }
   ],
   "source": [
    "# Try padding\n",
    "a_new = F.pad(a.T, pad=(1, a.T.shape[0] - a.T.shape[1] - 1))\n",
    "print(a_new.shape, a_new.numel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cf3672",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
